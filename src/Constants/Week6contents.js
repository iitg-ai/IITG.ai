export const Week6contents = [
  {
    text: "Day 1",
    message: "",
  },
  {
    text: `<p>
      Today we will be starting with basics of DL. First we will be seeing basics of DL and Neural Networks. Following this  a reference notebook is also there.   
      </p>`,
    message: "",
  },
  {
    text: `
        <p><u><a target="_blank" href="
        https://www.youtube.com/watch?v=aircAruvnKk
        ">
        Introduction to Neural Networks
        </a></u>
        </p>
  
          <br>
        <p>
        <u><a target="_blank" href="
        https://medium.com/@shaoliang.jia/why-is-deep-learning-taking-off-8244175929e7
        ">
        Why Deep Learning?
        </a></u>
        </p>
            `,
    message: ``,
  },
  {
    text: `
        <p><u><a target="_blank" href="
        https://www.youtube.com/watch?v=eqEc66RFY0I&list=PLpFsSf5Dm-pd5d3rjNtIXUHT-v7bdaEIe&index=7
        ">
        Neural Network for binary Classification
        </a></u>
        (Watch C1W2L01-C1W2L03)
        </p>
        
        `,
    message: "",
  },
  {
    text: `
          <p><u><a target="_blank" href="
          https://www.kaggle.com/code/kanncaa1/deep-learning-tutorial-for-beginners
          ">
          Practice Notebook
          </a></u>
          </p>
         `,
    message: ``,
  },

  {
    text: "Day 2",
    message: "",
  },
  {
    text: `
          <p>
          Following from yesterday, we will be seeing more about NN, mathematics behind it and how it works.
          </p>
        `,
    message: "",
  },
  {
    text: `
          <p><u><a target="_blank" href="
          https://youtu.be/IHZwWFHWa-w
          ">
          Gradient_Descent
          </a></u>
          </p>
            `,
    message: "",
  },
  {
    text: `
          <p><u><a target="_blank" href="
          https://www.youtube.com/watch?v=Ilg3gGewQ5U
          ">
          Intuition behind Backpropagation
          </a></u>
          </p> 
            `,
    message: "",
  },
  {
    text: `
          <p><u><a target="_blank" href="
          https://www.youtube.com/watch?v=tIeHLnjs5U8
          ">
          Calculations involved in Back Propagation
          </a></u>
          </p>
          <br>
          <p><u><a target="_blank" href="
          https://www.kaggle.com/code/kanncaa1/deep-learning-tutorial-for-beginners
          ">
          Practice notebook (Complete the remaining parts)
          </a></u>
          </p>
            `,
    message: ``,
  },

  {
    text: "Day 3",
    message: "",
  },
  {
    text: `
            <p>
            Today we will be starting with how to do calculations in a vectorized manner and more technical details of implementation
            
            </p>      
          `,
    message: "",
  },
  {
    text: `
        <p><u><a target="_blank" href="
        https://www.youtube.com/watch?v=qsIrQi0fzbY
        ">
        Vectorization_basics
        </a></u>
        </p>
          <br>
        <p><u><a target="_blank" href="
        https://www.youtube.com/watch?v=pYWASRauTzs
        ">
        More examples
        </a></u>
        </p>
          `,
    message: "",
  },
  {
    text: `
          <p><u><a target="_blank" href="
          https://www.kaggle.com/code/kanncaa1/vectorization-vs-non-vectorization
          ">
          Practice Notebook
          </a></u>
          </p>
          <br>
          <p><u><a target="_blank" href="
          https://www.youtube.com/watch?v=tKcLaGdvabM&list=PLpFsSf5Dm-pd5d3rjNtIXUHT-v7bdaEIe&index=21
          ">
          Broadcating_python
          </a></u>
          </p>
          `,
    message: "",
  },
  {
    text: `
          <p><u><a target="_blank" href="
          https://www.youtube.com/watch?v=eqEc66RFY0I&list=PLpFsSf5Dm-pd5d3rjNtIXUHT-v7bdaEIe&index=7
          ">
          Logistic Regression with vectorization
          </a></u>
      
          </p>
          `,
    message: ``,
  },

  {
    text: "Day 4",
    message: "",
  },
  {
    text: `
          <p>
          Continuing from yesterday , we will look into what are Activations and basics of it. Further we will be looking into Gradient Descent in NN and it’s calculations
          </p>
           `,
    message: "",
  },
  {
    text: `
          <p><u><a target="_blank" href="
          https://www.youtube.com/watch?v=xy5MOQpx3aQ&list=PLpFsSf5Dm-pd5d3rjNtIXUHT-v7bdaEIe&index=28
          ">
          Vectorization more details
          </a></u>
          (Watch C1W3L04-C1W3L05)
          </p>
          `,
    message: ``,
  },
  {
    text: `
          <p><u><a target="_blank" href="
          https://towardsdatascience.com/the-importance-and-reasoning-behind-activation-functions-4dc00e74db41
          ">
          Activations
          </a></u>
          </p>
          `,
    message: ``,
  },
  {
    text: `
          <p><u><a target="_blank" href="
          https://www.youtube.com/watch?v=7bLEWDZng_M&list=PLpFsSf5Dm-pd5d3rjNtIXUHT-v7bdaEIe&index=33
          ">
          Gradient descent in Neural Nets
          </a></u>
          </p>
          
          `,
    message: "",
  },

  {
    text: "Day 5",
    message: "",
  },
  {
    text: `
      Today we will be dealing with the initialization of weights and biases to different layers of NN and what are get into parameters and hyperparameters in the end.
      `,
    message: "",
  },
  {
    text: `
          <p><u><a target="_blank" href="
          https://www.deeplearning.ai/ai-notes/initialization/index.html
          ">
          Weight Initialization in Neural Networks
          </a></u>
          </p>
          `,
    message: ``,
  },
  {
    text: `
          <p><u><a target="_blank" href="
          https://youtu.be/2gw5tE2ziqA
          ">
          Deep_L_layer_network
          </a></u>
          </p>
          <br>
          <p><u><a target="_blank" href="
          https://youtu.be/qzPQ8cEsVK8
          ">
          Forward and backward propagations
          </a></u>
          </p>
          `,
    message: "",
  },
  {
    text: `
          <p><u><a target="_blank" href="
          https://youtu.be/VTE2KlfoO3Q
          ">
          Parameters and Hyperparameters
          </a></u>
          </p>
          `,
    message: ``,
  },

  {
    text: "Day 6",
    message: "",
  },
  {
    text: `
      Finally it’s the day to make a NN from scratch! A video is also provided and after that you can try creating from sklearn libraries with less code!
      `,
    message: "",
  },
  {
    text: `
          <p><u><a target="_blank" href="
          https://www.youtube.com/watch?v=w8yWXqWQYmU
          ">
          Make a neural network from scratch    
          </a></u>
          </p>
          `,
    message: ``,
  },
  {
    text: `
        <p><u><a target="_blank" href="
        https://www.youtube.com/watch?v=797iq6m64w0
        ">
        Neural Networks using Sklearn
        </a></u>
        </p>
        `,
    message: "",
  },
  {
    text: `
            <p><u><a target="_blank" href="
            https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html
            ">
            MLP documentation sklearn
            </a></u>
            </p>
          `,
    message: ``,
  },

  //   {
  //     text: "",
  //     message: "",
  //   },
  //   {
  //     text: "Assignments",
  //     message: "",
  //   },
  //   {
  //     text: `
  //               <p><a target="_blank" href="
  //               https://forms.gle/GKKhFJLdfZTLNx3EA
  //               "><u>Quiz : Live Now</u><a></p>
  //               `,
  //     message: "",
  //   },
  //   {
  //     text: `
  //         <p><a target="_blank" href="
  //         https://drive.google.com/file/d/1TNODmLpXrNhzNYuVkcHwy9CAkVbVSr6x/view?usp=sharing
  //         "><u>Assignment</u><a></p>
  //         `,
  //     message: "",
  //   },
  //   {
  //     text: "",
  //     message: "",
  //   },
];
